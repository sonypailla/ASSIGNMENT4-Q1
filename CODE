import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import nltk

# Download only stopwords (minimal and sufficient)
nltk.download('stopwords')

def preprocess_nlp(sentence):
    # 1. Tokenize using regular expressions (avoids punkt issues)
    tokens = re.findall(r'\b\w+\b', sentence)
    print("Original Tokens:", tokens)

    # 2. Remove stopwords
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]
    print("Tokens Without Stopwords:", filtered_tokens)

    # 3. Apply stemming
    stemmer = PorterStemmer()
    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]
    print("Stemmed Words:", stemmed_tokens)

# Run it
sentence = "NLP techniques are used in virtual assistants like Alexa and Siri."
preprocess_nlp(sentence)
